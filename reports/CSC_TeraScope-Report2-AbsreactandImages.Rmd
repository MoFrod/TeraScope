---
title: "CSC8634_TeraScope Structured Abstract and Key Images"
author: "Morgan Frodsham (210431461)"
date: "10/02/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
```

```{r ProjectTemplate, include = FALSE}
library(ProjectTemplate)
load.project()
```

## Structured Abstract
*243 Words*

**Context:** Newcastle University has built cloud (super)computer architecture for visualising environmental data captured by the Newcastle Urban Observatory as terapixels. For humankind to fully reap the benefits of the information provided by this technology, the computation needs to be efficient and associated costs must be sustainable.

**Objective:** This report explores the question: "How could the computation of a terapixel visualisation be more efficient?" to identify useful insights about computational performance, such as the stages of terapixel computation which are most resource intensive.

**Method:** This report details the exploratory data analysis used to wrangle and investigate three datasets created from the data produced by the (super)computer architecture during the creation of the terapixel visualisation. This analysis is conducted in R using the literate programming framework RMarkdown and CRISP-DM methodology.

**Result:** The analysis identifies that the run time is dominated by rendering the visualisation; rendering is more intensive when the visual content is more textured (for example, stadium seats or trees). We learn that tiling and uploading the visualisation, however, consume the most power. The analysis also suggests that the performance of the virtual machines divides into two groups because of GPU core utilisation and memory demand. We also learn which virtual machines are perpetually slow.

**Novelty:** These results offer insights into how the computation process could be improved. Run time, power consumption, GPU core utilisation and GPU memory demand are strong indicators of computation resource intensity and improving their efficiency will be vital in realising a sustainable technological future. 

## Key Images

### Image 1

```{R TPowerDuration1, echo = FALSE}
# Plot hostname by power draw and duration of total render
Power_Duration2 %>%
  filter(eventName == "TotalRender") %>%
  ggplot(aes(x = duration, y = powerDrawWatt, color = jobId)) + geom_point(position = "jitter") + labs(x = "Rendering Duration (seconds)", y = "Power Consumption (watts)", title = "Rendering a Terapixel: Power Consumption by Duration", color = "Visualisation Level") + scale_color_brewer(palette = "Paired") + theme(legend.position = "bottom") + guides(color = guide_legend(nrow = 3))
```

### Image 2

```{R mem.util, echo=FALSE, message=FALSE, warning=FALSE}
Performance <- GPU1 %>%
  group_by(hostname) %>% # Group by hostname
  summarise(av_power = mean(powerDrawWatt), sd_power = sd(powerDrawWatt), av_temp = mean(gpuTempC), sd_temp = sd(gpuTempC), av_util = mean(gpuUtilPerc), sd_util = sd(gpuUtilPerc), av_mem = mean(gpuMemUtilPerc), sd_mem = sd(gpuMemUtilPerc)) %>% # Calculate mean and standard deviation of power for each host.
  mutate(CoV_p = (sd_power/av_power)*100, CoV_t = (sd_temp/av_temp)*100, CoV_u = (sd_util/av_util)*100, CoV_m = (sd_mem/av_mem)*100) # New column with coefficient of variation

# Plot mem by util
Performance %>%
  ggplot(aes(x = av_mem, y = av_util, color = CoV_m)) + geom_point(position = "jitter") + geom_smooth(color = "#525252") + labs(x = "Average Memory (percentage)", y = "Average Core Utilisation (percentage)", title = "Virtual Machine GPU Core Utilisation by GPU Memory Demand", color = "Memory Variation") # Very clear trajectory of more memory corresponds to utilising  more gpu core
```